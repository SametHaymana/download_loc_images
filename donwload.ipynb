{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "\n",
    "# Change driver information to not detect bot\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "driver.execute_script(\"window.navigator.chrome = {runtime: {},  };\")\n",
    "driver.execute_script(\"window.navigator.permissions = {query: () => Promise.resolve({state: 'granted'}),  };\")\n",
    "driver.execute_script(\"const originalQuery = window.navigator.permissions.query; window.navigator.permissions.query = (parameters) => (parameters.name === 'notifications' ? Promise.resolve({state: Notification.permission}) : originalQuery(parameters));\")\n",
    "\n",
    "# Change user agent\n",
    "driver.execute_script(\"window.navigator.userAgent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\")\n",
    "\n",
    "\n",
    "# Wait for page to load\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_links = []\n",
    "\n",
    "for i in range(1,19):\n",
    "    table_links.append(f'https://www.loc.gov/pictures/search/?sp={i}&co=ahii&st=grid')\n",
    "\n",
    "print(table_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_page_urls = []\n",
    "\n",
    "def get_images_from_page(url:str):\n",
    "    driver.get(url)\n",
    "    # Wait for page to load\n",
    "    time.sleep(2)\n",
    "    # Get page source\n",
    "    html = driver.page_source\n",
    "    # Parse html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tbody = soup.find('tbody')\n",
    "    \n",
    "    if not tbody:\n",
    "        # Thwor error\n",
    "        raise Exception(\"No tbody found\")\n",
    "    \n",
    "    tds = tbody.find_all('td')\n",
    "    # Go every image page from td a href\n",
    "    for td in tds:\n",
    "        a = td.find('a')\n",
    "        if a:\n",
    "            href = a['href']\n",
    "            print(href)\n",
    "            image_page_urls.append(href)\n",
    "            \n",
    "for url in table_links:\n",
    "    get_images_from_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree \n",
    "\n",
    "image_name_urls = {}\n",
    "\n",
    "def get_image_from_page(url:str):\n",
    "    driver.get(url)\n",
    "    # Wait for page to load\n",
    "    time.sleep(2)\n",
    "    # Get page source\n",
    "    html = driver.page_source\n",
    "    # Parse html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    dom = etree.HTML(str(soup)) \n",
    "\n",
    "    # Get image Url with xpath\n",
    "    a = dom.xpath(\"/html/body/div[1]/div[5]/div[3]/div/div[4]/p[2]/a[4]\")[0]\n",
    "    \n",
    "    # Get href\n",
    "    href = a.attrib['href']\n",
    "    \n",
    "    # Get image name\n",
    "    name = dom.xpath('//*[@id=\"title\"]')[0].text\n",
    "    name = name.replace(\"[\",\"\").replace(\"]\",\"\").replace('\\n', '').replace(' ', '_').replace('/', '_').replace(':', '_').replace(\"\\t\", \"\").replace(\"\\r\", \"\").replace(\"\\xa0\", \"\").replace(\",\", \"\").replace(\".\", \"\").replace(\"?\", \"\").replace(\"!\", \"\").replace(\";\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\"’\", \"\").replace(\"‘\", \"\").replace(\"“\", \"\").replace(\"”\", \"\").replace(\"—\", \"\").replace(\"–\", \"\").replace(\"…\", \"\")\n",
    "    \n",
    "    \n",
    "    image_name_urls[name] = href\n",
    " \n",
    "\n",
    "for url in image_page_urls:\n",
    "    get_image_from_page(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(image_name_urls)\n",
    "print(len(image_name_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_bar\n",
    "\n",
    "# Create images folder\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "    \n",
    "\n",
    "with alive_bar(len(image_name_urls)) as bar:\n",
    "    for name, url in image_name_urls.items():\n",
    "        # Get image\n",
    "        response = requests.get(url)\n",
    "        # Save image\n",
    "        with open(f'images/{name}.tif', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        bar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
